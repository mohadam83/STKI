{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"RZE2ePoGDOvOYV2T0kiok8CL7\"\n",
    "api_secret_key = \"VF7LfzbEkOj5Mk3A4vizkSXZZiR5oDYYiNxTH78JJE3T6gMYvh\"\n",
    "access_token = \"814060411548905472-GsbJdyItSgF8hfpPsofKEHQV2RgiflW\"\n",
    "access_token_secret = \"8xgxwVBYazocQlEJid0KTKEbfkZB6CU84iltOLZxakrKO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"RZE2ePoGDOvOYV2T0kiok8CL7\"\n",
    "api_secret_key = \"VF7LfzbEkOj5Mk3A4vizkSXZZiR5oDYYiNxTH78JJE3T6gMYvh\"\n",
    "access_token = \"814060411548905472-GsbJdyItSgF8hfpPsofKEHQV2RgiflW\"\n",
    "access_token_secret = \"8xgxwVBYazocQlEJid0KTKEbfkZB6CU84iltOLZxakrKO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_29des = api.search(q=\"MAKING THE WORLD BRIGHT\", lang=\"id\", count=100)\n",
    "top2_29des = api.search(q=\"#JanganPercayaFPIMunafik\", lang=\"id\", count=100)\n",
    "top3_29des = api.search(q=\"#PeringatanGalonIsiUlangBPA\", lang=\"id\", count=100)\n",
    "top4_29des = api.search(q=\"#THEFIRSTSTEP_TREASUREEFFECT\", lang=\"id\", count=100)\n",
    "top5_29des = api.search(q=\"#RisalahAkhirTahun2020\", lang=\"id\", count=100)\n",
    "top6_29des = api.search(q=\"obl hilangkan izin berbelit\", lang=\"id\", count=100)\n",
    "top7_29des = api.search(q=\"#KhilafahAjaranIslam\", lang=\"id\", count=100)\n",
    "top8_29des = api.search(q=\"D3to2021 with iKON\", lang=\"id\", count=100)\n",
    "top9_29des = api.search(q=\"Rewind Indonesia 2020\", lang=\"id\", count=100)\n",
    "top10_29des = api.search(q=\"Pak Muh\", lang=\"id\", count=100)\n",
    "\n",
    "top11_29des = api.search(q=\"FPI Telah Berakhir\", lang=\"id\", count=100)\n",
    "top12_29des = api.search(q=\"#ByeByeDemocracy\", lang=\"id\", count=100)\n",
    "top13_29des = api.search(q=\"#ENHYPENonASC\", lang=\"id\", count=100)\n",
    "top14_29des = api.search(q=\"#StopTindakPidana\", lang=\"id\", count=100)\n",
    "top15_29des = api.search(q=\"#ENHYPEN ON AFTER SCHOOL CLUB\", lang=\"id\", count=100)\n",
    "top16_29des = api.search(q=\"#SpecialDJDoyoung\", lang=\"id\", count=100)\n",
    "top17_29des = api.search(q=\"Syafakillah\", lang=\"id\", count=100)\n",
    "top18_29des = api.search(q=\"Aa Gym\", lang=\"id\", count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "75\n",
      "7\n",
      "100\n",
      "100\n",
      "12\n",
      "100\n",
      "0\n",
      "100\n",
      "51\n",
      "56\n",
      "93\n",
      "7\n",
      "100\n",
      "0\n",
      "100\n",
      "100\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(top1_29des))\n",
    "print(len(top2_29des))\n",
    "print(len(top3_29des))\n",
    "print(len(top4_29des))\n",
    "print(len(top5_29des))\n",
    "print(len(top6_29des))\n",
    "print(len(top7_29des))\n",
    "print(len(top8_29des))\n",
    "print(len(top9_29des))\n",
    "print(len(top10_29des))\n",
    "print(len(top11_29des))\n",
    "print(len(top12_29des))\n",
    "print(len(top13_29des))\n",
    "print(len(top14_29des))\n",
    "print(len(top15_29des))\n",
    "print(len(top16_29des))\n",
    "print(len(top17_29des))\n",
    "print(len(top18_29des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @anyeonghashio: GANTENG NYA GAK MAUSIAWI üò≠üôè\n",
      "ADUH JANTUNG GUA KEK NYA UDAH PINDAH KE MATA KAKI DEH\n",
      "\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP‚Ä¶\n",
      "RT @anyeonghashio: GANTENG NYA GAK MAUSIAWI üò≠üôè ADUH JANTUNG GUA KEK NYA UDAH PINDAH KE MATA KAKI DEH  MAKING THE WORLD BRIGHT #THEFIRSTSTEP‚Ä¶\n",
      "----------\n",
      "RT @weirddoy: GIVEAWAY ALERT! \n",
      "\n",
      "üéÅ album only ch 3 black ver.\n",
      "üéÅ pc hyunsuk + 1st ed yoshi\n",
      "üéÅ pc jihoon + 1st ed jaehyuk\n",
      "\n",
      "syarat; reply pake t‚Ä¶\n",
      "RT @weirddoy: GIVEAWAY ALERT!   üéÅ album only ch 3 black ver. üéÅ pc hyunsuk + 1st ed yoshi üéÅ pc jihoon + 1st ed jaehyuk  syarat; reply pake t‚Ä¶\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    teks = top1_29des[i].text\n",
    "    print(teks)\n",
    "    teks = str(teks)\n",
    "    if(\"\\n\") in teks:\n",
    "        teks = teks.replace(\"\\n\", \" \")\n",
    "    print(teks)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import json\n",
    "\n",
    "# d_f = open(\"crawl_1.txt\", \"r\", encoding='utf-8')\n",
    "# isi_d_f = (d_f.readline())\n",
    "# # # isi_dict = ast.literal_eval(isi_d_f)\n",
    "# # js = json.loads(isi_d_f) \n",
    "# # print(type(js))\n",
    "# print(isi_d_f)\n",
    "# d_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isi_tweet': 'RT @weirddoy: GIVEAWAY ALERT! \\n\\nüéÅ album only ch 3 black ver.\\nüéÅ pc hyunsuk + 1st ed yoshi\\nüéÅ pc jihoon + 1st ed jaehyuk\\n\\nsyarat; reply pake t‚Ä¶'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "d_f = open(\"./crawl/crawl_1.txt\", \"r\", encoding='utf-8')\n",
    "isi_d_f = (d_f.readline())\n",
    "# # isi_dict = ast.literal_eval(isi_d_f)\n",
    "# js = json.loads(isi_d_f) \n",
    "# print(type(js))\n",
    "print(isi_d_f)\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_1.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_1.txt\"\n",
    "total = 0\n",
    "for i in range (len(top1_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top1_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top1_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top1_29des[i].text\n",
    "        f.write(str(top1_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1   \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_2.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_2.txt\"\n",
    "total = 0\n",
    "for i in range (len(top2_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top2_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top2_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top2_29des[i].text\n",
    "        f.write(str(top2_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_3.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_3.txt\"\n",
    "total = 0\n",
    "for i in range (len(top3_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top3_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top3_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top3_29des[i].text\n",
    "        f.write(str(top3_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_4.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_4.txt\"\n",
    "total = 0\n",
    "for i in range (len(top4_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top4_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top4_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top4_29des[i].text\n",
    "        f.write(str(top4_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_5.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_5.txt\"\n",
    "total = 0\n",
    "for i in range (len(top5_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top5_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top5_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top5_29des[i].text\n",
    "        f.write(str(top5_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_6.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_6.txt\"\n",
    "total = 0\n",
    "for i in range (len(top6_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top6_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top6_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top6_29des[i].text\n",
    "        f.write(str(top6_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_7.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_7.txt\"\n",
    "total = 0\n",
    "for i in range (len(top7_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top7_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top7_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top7_29des[i].text\n",
    "        f.write(str(top7_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_8.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_8.txt\"\n",
    "total = 0\n",
    "for i in range (len(top8_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top8_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top8_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top8_29des[i].text\n",
    "        f.write(str(top8_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_9.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_9.txt\"\n",
    "total = 0\n",
    "for i in range (len(top9_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top9_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top9_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top9_29des[i].text\n",
    "        f.write(str(top9_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_10.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_10.txt\"\n",
    "total = 0\n",
    "for i in range (len(top10_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top10_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top10_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top10_29des[i].text\n",
    "        f.write(str(top10_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_11.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_11.txt\"\n",
    "total = 0\n",
    "for i in range (len(top11_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top11_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top11_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top11_29des[i].text\n",
    "        f.write(str(top11_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_12.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_12.txt\"\n",
    "total = 0\n",
    "for i in range (len(top12_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top12_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top12_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top12_29des[i].text\n",
    "        f.write(str(top12_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_13.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_13.txt\"\n",
    "total = 0\n",
    "for i in range (len(top13_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top13_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top13_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top13_29des[i].text\n",
    "        f.write(str(top13_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_14.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_14.txt\"\n",
    "total = 0\n",
    "for i in range (len(top14_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top14_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top14_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top14_29des[i].text\n",
    "        f.write(str(top14_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_15.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_15.txt\"\n",
    "total = 0\n",
    "for i in range (len(top15_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top15_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top15_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top15_29des[i].text\n",
    "        f.write(str(top15_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_16.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_16.txt\"\n",
    "total = 0\n",
    "for i in range (len(top16_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top16_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top16_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top16_29des[i].text\n",
    "        f.write(str(top16_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_17.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_17.txt\"\n",
    "total = 0\n",
    "for i in range (len(top17_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top17_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top17_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top17_29des[i].text\n",
    "        f.write(str(top17_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "cek_in = list()\n",
    "nama_file = \"./crawl/crawl_18.txt\"\n",
    "nama_file_unik = \"./crawlId/crawlId_18.txt\"\n",
    "total = 0\n",
    "for i in range (len(top18_29des)):\n",
    "    f = open(nama_file_unik, \"r\")\n",
    "    if(top18_29des[i].id_str in f.read()):\n",
    "        cek_in.append(\"1\")\n",
    "    else:\n",
    "        cek_in.append(\"0\")\n",
    "        total += 1\n",
    "#         print(\"belum ada : \" + str(top1_29des[i].id_str))\n",
    "    f.close()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f = open(nama_file_unik, \"a+\")\n",
    "d_f = open(nama_file, \"a+\", encoding='utf-8')\n",
    "total = 0\n",
    "for i in range (len(top18_29des)):\n",
    "    if(cek_in[i] == '0'):\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"isi_tweet\"] = top18_29des[i].text\n",
    "        f.write(str(top18_29des[i].id_str))\n",
    "        f.write(\"\\n\")\n",
    "        d_f.write(str(tweet_properties))\n",
    "        d_f.write(\"\\n\")\n",
    "        total += 1\n",
    "        \n",
    "print(total)\n",
    "print(\"----------------------------------------\")\n",
    "f.close()\n",
    "d_f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "-------------\n",
      "1344191683999645696\n",
      "belom ada\n",
      "[]\n",
      "-------------\n",
      "1344191683999645696\n",
      "belom ada\n"
     ]
    }
   ],
   "source": [
    "nama_file = \"crawl_\" + str(count) + \".txt\"\n",
    "nama_file_id = \"crawlId_\" + str(count) + \".txt\"\n",
    "\n",
    "with open(nama_file, 'a+') as file:\n",
    "#     for tweet in top1_29des:\n",
    "        f = open(nama_file_id, \"a+\")\n",
    "        for i in range (2):\n",
    "            print(f.readlines())\n",
    "            print(\"-------------\")\n",
    "            print(top1_29des[0].id_str)\n",
    "            if top1_29des[0].id_str in f.read():\n",
    "                print(\"sudah ada\")\n",
    "    #             continue\n",
    "            else:\n",
    "                print(\"belom ada\")\n",
    "                f.write(\"%s\\n\" % top1_29des[0].id_str)\n",
    "        f.close()\n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @09JUNKYUTIES @riakirakha Bismillahirrahmanirrahim done wish yas luck‚ú® nanti yas kasih thread Streaming kalo udh tg‚Ä¶ https://t.co/mSQMCzaJ4t\n",
      "cleansing : Bismillahirrahmanirrahim done wish yas luck nanti yas kasih thread Streaming kalo udh tg\n",
      "belom ada\n",
      "Awal : @weirddoy done, bismillah wish me luckü•∫\n",
      "sebelumnya makasihh bgt udh ngadain GAnyaü•∞, semoga rezekinya dilancarkan te‚Ä¶ https://t.co/yTIgBlGhM3\n",
      "cleansing : done bismillah wish me luck sebelumnya makasihh bgt udh ngadain GAnya semoga rezekinya dilancarkan te\n",
      "belom ada\n",
      "Awal : @treasureyouco @treasuremembers done kak! bismillah smg rejeki aku aamiin.. ‚ò∫Ô∏èüôèüèª\n",
      "\n",
      "MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/3yYb3xAqc7\n",
      "cleansing : done kak bismillah smg rejeki aku aamiin MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @papermer itula..msti kecoh satu rmh kata mbazir..hahaha\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT‚Ä¶ https://t.co/rnMNKMQL6Q\n",
      "cleansing : itula msti kecoh satu rmh kata mbazir hahaha MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT\n",
      "belom ada\n",
      "Awal : @diaegiya Done, thankyou for GA wish me luck‚ô°\n",
      "Semoga treasure kedepannya makin sukses, makin byk yg cinta &amp; syg, ma‚Ä¶ https://t.co/Y8Eo4yDjkP\n",
      "cleansing : Done thankyou for GA wish me luck Semoga treasure kedepannya makin sukses makin byk yg cinta amp syg ma\n",
      "belom ada\n",
      "Awal : @weirddoy Bismillah bisa ü§≤üèª\n",
      "Big thanks to kakak yg udh ngadain GA ini^^ semoga rezeki nya lancar terus kea sungai,‚Ä¶ https://t.co/0TZF4pdQOe\n",
      "cleansing : Bismillah bisa Big thanks to kakak yg udh ngadain GA ini semoga rezeki nya lancar terus kea sungai\n",
      "belom ada\n",
      "Awal : @hikunforasahi @treasuremembers Terima kasih banyak karena udah adain GA ini, semoga menang kali ini Ya Allahüòî, Bis‚Ä¶ https://t.co/YfwP0QtvMz\n",
      "cleansing : Terima kasih banyak karena udah adain GA ini semoga menang kali ini Ya Allah Bis\n",
      "belom ada\n",
      "Awal : @nikonikoni2_ Bismillah, wish me luck. Aminüôèüèª\n",
      "\n",
      "Btw, makasih udah ngadain GAü•∫ Sukses selalu, stay healthy and please‚Ä¶ https://t.co/HbyaCcnxM3\n",
      "cleansing : Bismillah wish me luck Amin Btw makasih udah ngadain GA Sukses selalu stay healthy and please\n",
      "belom ada\n",
      "Awal : @diaegiya Done, thankyou for GA, wish me luck. smoga treasure kedepannya makin sukses, makin banyak penggemar, semu‚Ä¶ https://t.co/F4H98ikSqO\n",
      "cleansing : Done thankyou for GA wish me luck smoga treasure kedepannya makin sukses makin banyak penggemar semu\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @weirddoy pertama makasi ya kak udah adain ga ini bnrn terharu bgt bahkan ga mnta di follow, like sm rt sesungguhny‚Ä¶ https://t.co/w9QyChCRzO\n",
      "cleansing : pertama makasi ya kak udah adain ga ini bnrn terharu bgt bahkan ga mnta di follow like sm rt sesungguhny\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @diaegiya Done, thankyou for GA‚ô°‚ô° wish me luck‚ô°‚ô°\n",
      "Moga treasure kedepannya makin sukses, makin banyak yg syg, makin‚Ä¶ https://t.co/dy5UdqamgS\n",
      "cleansing : Done thankyou for GA wish me luck Moga treasure kedepannya makin sukses makin banyak yg syg makin\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @ygtreasurehd @treasuremembers Uncuk.. bunga bunga nya kalah seger. Ungu ungu\n",
      "\n",
      "MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/dTqtm6OMDQ\n",
      "cleansing : Uncuk bunga bunga nya kalah seger Ungu ungu MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "Awal : @weirddoy Bismilah semoga menang..\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT #TREASURE\n",
      "cleansing : Bismilah semoga menang MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT TREASURE\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @asharutoz bismillahirrahmanirrahim done, kakak dom Bandung yaa? kujuga dom Bandung kakkk hehe, semoga rezekinya la‚Ä¶ https://t.co/biUMTt9n7G\n",
      "cleansing : bismillahirrahmanirrahim done kakak dom Bandung yaa kujuga dom Bandung kakkk hehe semoga rezekinya la\n",
      "belom ada\n",
      "Awal : @09JUNKYUTIES @riakirakha Bismillah, done. Makasi ka asya udh adain GA ü•∫ semoga kali ini rezeki hehe, blm prnh mena‚Ä¶ https://t.co/7kyOPIWgih\n",
      "cleansing : Bismillah done Makasi ka asya udh adain GA semoga kali ini rezeki hehe blm prnh mena\n",
      "belom ada\n",
      "Awal : @jihoonunaaaaa bismillah, doneee ka !!&lt;33 wml huhu, aku mau album ka üò≠ü•∞\n",
      "\n",
      "MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/7Xhlbo3Rok\n",
      "cleansing : bismillah doneee ka lt 33 wml huhu aku mau album ka MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "Awal : @weirddoy Done, bismillahirrahmanirrahimüôè\n",
      "Makasih buat GA nya smoga rejekinya lancar trus aminn dan smoga kali ini‚Ä¶ https://t.co/K0Wt5tRVAa\n",
      "cleansing : Done bismillahirrahmanirrahim Makasih buat GA nya smoga rejekinya lancar trus aminn dan smoga kali ini\n",
      "belom ada\n",
      "Awal : @DearMe_kr doneee ! &lt;3 makasi udh buat ga ka, wml üò≠ü•∞ü•∞\n",
      "\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT‚Ä¶ https://t.co/hlhRzo2DDR\n",
      "cleansing : kr doneee lt 3 makasi udh buat ga ka wml MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @goharukyu @treasuremembers Bismillah semoga dapat , sukses terus ‚ù§\n",
      "MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/5NwRAZLZvs\n",
      "cleansing : Bismillah semoga dapat sukses terus MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @wntwans @guchilsGO Done, bismillahüôè\n",
      "Alasan pgn bgt album ini karna ak blm punya satupun album aplagi album treasur‚Ä¶ https://t.co/E5Z5KypQzN\n",
      "cleansing : Done bismillah Alasan pgn bgt album ini karna ak blm punya satupun album aplagi album treasur\n",
      "belom ada\n",
      "Awal : @junkyutrashh @treasuremembers My motto is ‚Äúlebih baik menyesal membeli daripada menyesal tidak membeli‚Äù so I bough‚Ä¶ https://t.co/F6Mig1pk3R\n",
      "cleansing : My motto is lebih baik menyesal membeli daripada menyesal tidak membeli so I bough\n",
      "belom ada\n",
      "Awal : @nikonikoni2_ Done, bismillahüôè\n",
      "Makasih buat GA nya\n",
      "Wish me luck‚ú®\n",
      "\n",
      "MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/ExMdwnmCcL\n",
      "cleansing : Done bismillah Makasih buat GA nya Wish me luck MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "Awal : @istriyedam Done, bismillahüôè semoga rezeki ku amin yaallah.. Btw makasih banyak udah ngadain GA ini semoga rezeki n‚Ä¶ https://t.co/lyzyaXozQx\n",
      "cleansing : Done bismillah semoga rezeki ku amin yaallah Btw makasih banyak udah ngadain GA ini semoga rezeki n\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @weirddoy Done, makasih banyak udah adain GA ka semoga rezekinya makin dilancarkan juga sehat selalu üôå\n",
      "Wish me luck‚Ä¶ https://t.co/yhmewxOQfA\n",
      "cleansing : Done makasih banyak udah adain GA ka semoga rezekinya makin dilancarkan juga sehat selalu Wish me luck\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @nikonikoni2_ done kak!‚ô• thanks for the giveaway, lancar terus ya kak rezekinyaaa.. jgn lupa pake masker... wmlüôè\n",
      "\n",
      "M‚Ä¶ https://t.co/1I47WkjTQP\n",
      "cleansing : done kak thanks for the giveaway lancar terus ya kak rezekinyaaa jgn lupa pake masker wml M\n",
      "belom ada\n",
      "Awal : Pagi teume, ayok belajar, jangan lupa Rep # !!!!\n",
      "\n",
      "1. Pada tanggal berapakah hari pahlawan 2020?\n",
      "\n",
      "MAKING THE WORLD B‚Ä¶ https://t.co/HitgpvT5Vo\n",
      "cleansing : Pagi teume ayok belajar jangan lupa Rep 1 Pada tanggal berapakah hari pahlawan 2020 MAKING THE WORLD B\n",
      "belom ada\n",
      "Awal : @nikonikoni2_ done, bismillah thanks for GA smoga rezekinya dipermudah dan dilancarkan terus. wish me luck~\n",
      "\n",
      "MAKING‚Ä¶ https://t.co/csQ8IWQCjk\n",
      "cleansing : done bismillah thanks for GA smoga rezekinya dipermudah dan dilancarkan terus wish me luck MAKING\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @treasuremenfess gatau nder gabelajar akuntan\n",
      "\n",
      "MAKING THE WORLD BRIGHT #THEFIRSTSTEP_TREASUREEFFECT #TREASURE #Ìä∏Î†àÏ†Ä @treasuremembers\n",
      "cleansing : gatau nder gabelajar akuntan MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT TREASURE\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @treasureyouco @treasuremembers Bismillah done. Wish me lucküôè\n",
      "Semoga menang, pengen bgt ngerasain punya album huhuü•∫‚Ä¶ https://t.co/gRMlxrqnDE\n",
      "cleansing : Bismillah done Wish me luck Semoga menang pengen bgt ngerasain punya album huhu\n",
      "belom ada\n",
      "Awal : @wntwans @guchilsGO all rules done kak!  makasih buat giveawaynya kak semoga rezeki kakak lancar terus ya kaa ‚ô•  wm‚Ä¶ https://t.co/sYiKfiqd6l\n",
      "cleansing : all rules done kak makasih buat giveawaynya kak semoga rezeki kakak lancar terus ya kaa wm\n",
      "belom ada\n",
      "Awal : @treasuremenfess kenapa juga Jungwhan kelihatan pendek bgt disebelah Haruto??padahal tinggi mereka nggak seberapa!!‚Ä¶ https://t.co/yMhY2tcjeX\n",
      "cleansing : kenapa juga Jungwhan kelihatan pendek bgt disebelah Haruto padahal tinggi mereka nggak seberapa\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @treasuremenfess Sarapannya beres\" rumah dulu dahh\n",
      "\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT #TREASURE #Ìä∏Î†àÏ†Ä \n",
      "@treasuremembers\n",
      "cleansing : Sarapannya beres rumah dulu dahh MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT TREASURE\n",
      "belom ada\n",
      "Awal : @treasuremenfess Aku mam gorengan dulu biar mantep\n",
      "\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT\n",
      "#TREASURE #Ìä∏Î†àÏ†Ä\n",
      "@treasuremembers\n",
      "cleansing : Aku mam gorengan dulu biar mantep MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT TREASURE\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @istriyedam all rules done kak!  makasih buat giveawaynya kak semoga rezeki kakak lancar terus ya kaa ‚ô•  wmlüôè\n",
      "\n",
      "JULE‚Ä¶ https://t.co/quTkOYPLoH\n",
      "cleansing : all rules done kak makasih buat giveawaynya kak semoga rezeki kakak lancar terus ya kaa wml JULE\n",
      "belom ada\n",
      "Awal : @weirddoy Bismillah semoga kali ini aku bisa dpt makasih buat kaka nya yg udh mau adain GA\n",
      "\n",
      "MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/okuilR3jPb\n",
      "cleansing : Bismillah semoga kali ini aku bisa dpt makasih buat kaka nya yg udh mau adain GA MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "Awal : @Stormwonu @Hachibae81 all rules done kak!  makasih buat giveawaynya kak semoga rezeki kakak lancar terus ya kaa ‚ô•‚Ä¶ https://t.co/42OOrcSzTW\n",
      "cleansing : all rules done kak makasih buat giveawaynya kak semoga rezeki kakak lancar terus ya kaa\n",
      "belom ada\n",
      "Awal : Memang sengaja taknak bagi kita tunggu. Surprise konon nya. MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT‚Ä¶ https://t.co/VsEok9Igfd\n",
      "cleansing : Memang sengaja taknak bagi kita tunggu Surprise konon nya MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT\n",
      "belom ada\n",
      "Awal : @DearMe_kr Bismillah wish me luck‚ô°‚ô°makasi bgt buat GAnya&gt;&lt;\n",
      "\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT‚Ä¶ https://t.co/w5zPljsDHJ\n",
      "cleansing : kr Bismillah wish me luck makasi bgt buat GAnya gt lt MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @yojiharu Done, thankyou for GA‚ô°‚ô° wish me luck‚ô°‚ô°\n",
      "Wishnya moga ditahun 2021 lebih baik lagi dari sebalumnya, apa yg‚Ä¶ https://t.co/ak90UkKPqT\n",
      "cleansing : Done thankyou for GA wish me luck Wishnya moga ditahun 2021 lebih baik lagi dari sebalumnya apa yg\n",
      "belom ada\n",
      "Awal : @istriyedam done bismillah thanks for ga kajul‚ô° smoga rezekinya dilancarkan trus,amiinn. Wish me luck‚ú®üôè\n",
      "\n",
      "juledam \n",
      "j‚Ä¶ https://t.co/FhmKGchtw8\n",
      "cleansing : done bismillah thanks for ga kajul smoga rezekinya dilancarkan trus amiinn Wish me luck juledam j\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @treasureyouco @treasuremembers Done\n",
      "Bismillah , Semoga aku menang ü•∫üôè\n",
      "Thank you so much buat GA nya kak\n",
      "Semoga reje‚Ä¶ https://t.co/c4PliOoyFa\n",
      "cleansing : Done Bismillah Semoga aku menang Thank you so much buat GA nya kak Semoga reje\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @09JUNKYUTIES @riakirakha Done\n",
      "\n",
      "Bismillah , Semoga aku bisa menang ü•∫üôè\n",
      "Makasih banyak kak buat GA nya , Semoga rejek‚Ä¶ https://t.co/ZBsQfj2efP\n",
      "cleansing : Done Bismillah Semoga aku bisa menang Makasih banyak kak buat GA nya Semoga rejek\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @weirddoy Bismillah ya allah semoga rezekinya aku aamiin aamiin. Thank u so much buat GA nya kak. Semoga rezeki kak‚Ä¶ https://t.co/jaHNB8d0dK\n",
      "cleansing : Bismillah ya allah semoga rezekinya aku aamiin aamiin Thank u so much buat GA nya kak Semoga rezeki kak\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @jihoonunaaaaa Mau albuuuum\n",
      "\n",
      "smoga aku menang GA ini\n",
      "smoga rezekinya dilancarkan, kedepannya kk semakin sukses Aami‚Ä¶ https://t.co/26ER6RuBo1\n",
      "cleansing : Mau albuuuum smoga aku menang GA ini smoga rezekinya dilancarkan kedepannya kk semakin sukses Aami\n",
      "belom ada\n",
      "Awal : good morning teum! pagi-pagi gini enaknya ngebadut ya, hehe \n",
      "\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT‚Ä¶ https://t.co/VxRarD2hew\n",
      "cleansing : good morning teum pagi pagi gini enaknya ngebadut ya hehe MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @weirddoy Makasih banyak udah ngadain GA!!\n",
      "\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT\n",
      "#TREASURE #Ìä∏Î†àÏ†Ä\n",
      "@treasuremembers\n",
      "cleansing : Makasih banyak udah ngadain GA MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT TREASURE\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @treasureyouco DONE KAK,\n",
      "bismillahirrahmanirrahim semoga rezeki üòª\n",
      "makasih udah buat giveawaynya üòª\n",
      " \n",
      "MAKING THE WORL‚Ä¶ https://t.co/JbPR4oufg3\n",
      "cleansing : DONE KAK bismillahirrahmanirrahim semoga rezeki makasih udah buat giveawaynya MAKING THE WORL\n",
      "belom ada\n",
      "Awal : @treasureyouco @treasuremembers done, makasih kak udah adain giveaway. bismillah semoga beruntungü•∫üíó\n",
      "\n",
      "MAKING THE WOR‚Ä¶ https://t.co/716JfVJN7K\n",
      "cleansing : done makasih kak udah adain giveaway bismillah semoga beruntung MAKING THE WOR\n",
      "belom ada\n",
      "Awal : @weirddoy donee, bismillah wml huhu, makasih udah ngadain GA, semoga rejekinya dilancarkan dan sukses selalu kaaüôèüèª‚Ä¶ https://t.co/0Kgk7l0QsD\n",
      "cleansing : donee bismillah wml huhu makasih udah ngadain GA semoga rejekinya dilancarkan dan sukses selalu kaa\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @nikonikoni2_ Done. Wish me luck. Makasih udah ngadain GA\n",
      "\n",
      "MAKING THE WORLD BRIGHT\n",
      "#THEFIRSTSTEP_TREASUREEFFECT‚Ä¶ https://t.co/ynZ8zwlgMo\n",
      "cleansing : Done Wish me luck Makasih udah ngadain GA MAKING THE WORLD BRIGHT THEFIRSTSTEP TREASUREEFFECT\n",
      "belom ada\n",
      "Awal : @Stormwonu @Hachibae81 Done, wml. Makasih ka udah ngadain GA semoga rezekinya lancar terus\n",
      "\n",
      "MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/q0VQlp3kNK\n",
      "cleansing : Done wml Makasih ka udah ngadain GA semoga rezekinya lancar terus MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : Wehhhhhhhhhh aku noticeee ni HAHAHAHAHAHS aku pelik la asal ebit lew punyer music sama hyunsuk punye  video üòÇüòÇüòÇ \n",
      "\n",
      "M‚Ä¶ https://t.co/OGqIsDwP33\n",
      "cleansing : Wehhhhhhhhhh aku noticeee ni HAHAHAHAHAHS aku pelik la asal ebit lew punyer music sama hyunsuk punye video M\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @weirddoy Done\n",
      "Bismillah,semoga aku beruntungü§≤üèª\n",
      "Makasih GA nya ya,sehat selalu buat kamu‚ú®\n",
      "\n",
      " MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/WYRxuYgrqL\n",
      "cleansing : Done Bismillah semoga aku beruntung Makasih GA nya ya sehat selalu buat kamu MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "Awal : @nikonikoni2_ Done kak.. wish me lucküåπ semoga yg ini rejeki ku... Makasih buat kakak sebelumnya udah ngadain give a‚Ä¶ https://t.co/6s8QpCtSM4\n",
      "cleansing : Done kak wish me luck semoga yg ini rejeki ku Makasih buat kakak sebelumnya udah ngadain give a\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "Awal : @weirddoy @dobbyjuchann Done, bismillahüôè semoga rejeki lah yaa‚ò∫Ô∏èü§ß\n",
      "\n",
      "MAKING THE WORLD BRIGHT‚Ä¶ https://t.co/U37sdDqzI3\n",
      "cleansing : Done bismillah semoga rejeki lah yaa MAKING THE WORLD BRIGHT\n",
      "belom ada\n",
      "skip\n",
      "belom ada\n",
      "skip\n"
     ]
    }
   ],
   "source": [
    "top1_29desAnalisis = []\n",
    "top2_29desAnalisis = []\n",
    "top3_29desAnalisis = []\n",
    "top4_29desAnalisis = []\n",
    "top5_29desAnalisis = []\n",
    "top6_29desAnalisis = []\n",
    "top7_29desAnalisis = []\n",
    "top8_29desAnalisis = []\n",
    "top9_29desAnalisis = []\n",
    "top10_29desAnalisis = []\n",
    "top11_29desAnalisis = []\n",
    "top12_29desAnalisis = []\n",
    "top13_29desAnalisis = []\n",
    "top14_29desAnalisis = []\n",
    "top15_29desAnalisis = []\n",
    "top16_29desAnalisis = []\n",
    "top17_29desAnalisis = []\n",
    "top18_29desAnalisis = []\n",
    "\n",
    "hasil_sentiment_pos = 0\n",
    "hasil_sentiment_net = 0\n",
    "hasil_sentiment_neg = 0\n",
    "\n",
    "count = 1\n",
    "nama_file = \"crawl_\" + str(count) + \".txt\"\n",
    "nama_file_id = \"crawlId_\" + str(count) + \".txt\"\n",
    "\n",
    "with open(nama_file, 'a+') as file:\n",
    "    for tweet in top1_29des:\n",
    "        f = open(nama_file_id, \"a+\")\n",
    "        f.read()\n",
    "        if tweet.id_str in f.read():\n",
    "            print(\"sudah ada\")\n",
    "            continue\n",
    "        else:\n",
    "            print(\"belom ada\")\n",
    "            f.write(\"%s\\n\" % tweet.id_str)\n",
    "        f.close()\n",
    "        tweet_properties = {}\n",
    "        tweet_properties[\"tanggal_tweet\"] = tweet.created_at\n",
    "        tweet_properties[\"pengguna\"] = tweet.user.screen_name\n",
    "        tweet_bersih = tweet.text\n",
    "        # print(tweet_bersih)\n",
    "        # SELEKSI KOMENTAR dari Retweet dihilangkan\n",
    "        # check if the tweet starts with the format for a retweet \n",
    "        if tweet_bersih.startswith(\"RT @\") == True:\n",
    "            print(\"skip\")\n",
    "            # print(\"skip : \" + tweet_bersih)\n",
    "            continue\n",
    "        print(\"Awal : \" + tweet_bersih)  \n",
    "\n",
    "        # MENGHILANGKAN EMOJI\n",
    "        #remove emoji from tweet\n",
    "        tweet_bersih = emoji_pattern.sub(r'', tweet_bersih)\n",
    "        # print(\"emoticon : \" + tweet_bersih)  \n",
    "\n",
    "        # NORMALISASI KALIMAT (mengubah menjadi lower case)\n",
    "        tweet_bersih = str(tweet_bersih.lower().encode('ascii',errors='ignore'))\n",
    "        # print(\"normalisasi : \" + tweet_bersih)\n",
    "\n",
    "        # CLEANSING (menghilangkan @, url, email, website)\n",
    "        tweet_bersih = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet.text).split())\n",
    "        print(\"cleansing : \" + tweet_bersih)\n",
    "\n",
    "        tweet_properties[\"isi_tweet\"] = tweet_bersih\n",
    "#         tweet_properties[\"isi_tweet\"] = tweet.id_str\n",
    "        top1_29desAnalisis.append(tweet_properties)\n",
    "        file.write(str(tweet_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @RumahSelebMNCTV: Joged tiktok sore - sore emang paling cocok. Apalagi kalo joged tiktoknya sama artis -artis kece ü§ó\n",
      "..\n",
      "Yukk cuss nonton‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "hasilAnalisis = []\n",
    "for tweet in hasilSearch:\n",
    "    tweet_properties = {}\n",
    "    tweet_properties[\"tanggal_tweet\"] = tweet.created_at\n",
    "    tweet_properties[\"pengguna\"] = tweet.user.screen_name\n",
    "    \n",
    "    tweet_bersih = tweet.text\n",
    "    \n",
    "    # could go without this variable it just makes it easier\n",
    "#     tweet_bersih = str(tweet_bersih.lower().encode('ascii',errors='ignore'))\n",
    "#     print(tweet_bersih)\n",
    "    # check if the tweet starts with the format for a retweet\n",
    "    if tweet_bersih.startswith(\"RT @\") == True:\n",
    "        print(tweet_bersih)\n",
    "        continue\n",
    "        \n",
    "    tweet_bersih = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet.text).split())\n",
    "    tweet_properties[\"isi_tweet\"] = tweet_bersih\n",
    "#     print(tweet_bersih)\n",
    "#     analysis = TextBlob(tweet_bersih)\n",
    "    \n",
    "#     try:\n",
    "#         analysis = analysis.translate(to=\"en\")\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "    \n",
    "#     if analysis.sentiment.polarity > 0.0:\n",
    "#         tweet_properties[\"sentimen\"] = \"positif\"\n",
    "#     elif analysis.sentiment.polarity == 0.0:\n",
    "#         tweet_properties[\"sentimen\"] = \"netral\"\n",
    "#     else:\n",
    "#         tweet_properties[\"sentimen\"] = \"negatif\"\n",
    "    \n",
    "    \n",
    "    if tweet.retweet_count > 0:\n",
    "        if tweet_properties not in hasilAnalisis:\n",
    "            hasilAnalisis.append(tweet_properties)\n",
    "    else:\n",
    "        hasilAnalisis.append(tweet_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(hasilAnalisis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-11 08:10:41\n",
      "kami akan reveal di tanggal 12 hehehehehe\n",
      "-------------------------------------------------------\n",
      "2020-11-27 03:05:09\n",
      "\n",
      "-------------------------------------------------------\n",
      "2020-11-21 06:11:40\n",
      "Sekali kali Bangun Siaaang Oh Indahnya\n",
      "-------------------------------------------------------\n",
      "2020-11-13 11:08:09\n",
      "Vespa Pink\n",
      "-------------------------------------------------------\n",
      "2020-11-09 12:23:20\n",
      "Jail bgt nih rafatar kayak bapake\n",
      "-------------------------------------------------------\n",
      "2020-11-07 02:58:20\n",
      "Good Morning\n",
      "-------------------------------------------------------\n",
      "2020-11-06 14:16:56\n",
      "sunset time\n",
      "-------------------------------------------------------\n",
      "2020-11-05 13:28:53\n",
      "\n",
      "-------------------------------------------------------\n",
      "2020-11-05 13:28:32\n",
      "Ajak dia LibuRans Gimana Guys Kayaknya seruuu bamgetttt\n",
      "-------------------------------------------------------\n",
      "2020-08-22 11:37:29\n",
      "GOKIL RAFFI NAGITA GAK MAU KALAH DARI MAMA RIETA BORONG APARTEMENT SA via\n",
      "-------------------------------------------------------\n",
      "2020-07-08 01:02:49\n",
      "Tapi\n",
      "-------------------------------------------------------\n",
      "2020-07-08 01:01:50\n",
      "\n",
      "-------------------------------------------------------\n",
      "2020-07-07 16:03:07\n",
      "Iyaa betul sampai 10 juli yaa\n",
      "-------------------------------------------------------\n",
      "2020-07-07 01:42:26\n",
      "GoodMorning\n",
      "-------------------------------------------------------\n",
      "2020-07-06 13:58:27\n",
      "Hello Guys\n",
      "-------------------------------------------------------\n",
      "2020-07-04 03:30:02\n",
      "Salam buat wilson\n",
      "-------------------------------------------------------\n",
      "2020-07-02 07:17:27\n",
      "Cinta Luar Biasa\n",
      "-------------------------------------------------------\n",
      "2020-07-02 07:15:31\n",
      "Iyak betul\n",
      "-------------------------------------------------------\n",
      "2020-06-30 11:29:01\n",
      "Bakal dipilih 1 pemenang beruntung memenangkan album Reload yang ada tanda tangan member NCT Dream Pemenang baka\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for tweet in hasilAnalisis:\n",
    "    print(tweet[\"tanggal_tweet\"])\n",
    "#     print(tweet[\"pengguna\"])\n",
    "    print(tweet[\"isi_tweet\"])\n",
    "    print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_positif = [t for t in hasilAnalisis if t[\"sentimen\"]==\"positif\"]\n",
    "tweet_netral = [t for t in hasilAnalisis if t[\"sentimen\"]==\"netral\"]\n",
    "tweet_negatif = [t for t in hasilAnalisis if t[\"sentimen\"]==\"negatif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Sentimen\n",
      "positif:  8\n",
      "netral:  56\n",
      "negatif:  36\n"
     ]
    }
   ],
   "source": [
    "print(\"Hasil Sentimen\")\n",
    "print(\"positif: \", len(tweet_positif))\n",
    "print(\"netral: \", len(tweet_netral))\n",
    "print(\"negatif: \", len(tweet_negatif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 37),\n",
       "  'pengguna': 'AndalCoi',\n",
       "  'isi_tweet': 'jual netflix premium antihold\\n\\nSHARING\\n30k/BULAN, 90K/3 BLN\\n\\nPRIVATE\\n135k/BLN, 330K/3BLN\\n\\n‚ö†Ô∏èAPP LAIN CEK PINNED\\n\\nsp‚Ä¶ https://t.co/pfJqllMOhw',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 36, 5),\n",
       "  'pengguna': 'diyajengg',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 33, 46),\n",
       "  'pengguna': 'adriansah_alief',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 30, 59),\n",
       "  'pengguna': 'michfactory',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 30, 7),\n",
       "  'pengguna': 'skinnyfatguyyy',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 27, 59),\n",
       "  'pengguna': 'soniapr10',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 22, 5),\n",
       "  'pengguna': 'resannst',\n",
       "  'isi_tweet': 'RT @ismerobi: Segede apapun Gaji Jakarta kalo Lu hidup di sana juga yaa percuma bambang. https://t.co/sBKk9y0cmy',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 19, 44),\n",
       "  'pengguna': 'ffajrin_',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 19, 42),\n",
       "  'pengguna': 'sstrongerrr',\n",
       "  'isi_tweet': 'RT @Sketsa_Rasa: „Ö§„Ö§\\nPercuma gaji jakarta, biaya hidup jogja, kalo suasana udah di padang mahsyar mah semua nggak ada gunanya.\\n„Ö§„Ö§',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 15, 59),\n",
       "  'pengguna': 'balbalp_',\n",
       "  'isi_tweet': 'RT @Sketsa_Rasa: „Ö§„Ö§\\nPercuma gaji jakarta, biaya hidup jogja, kalo suasana udah di padang mahsyar mah semua nggak ada gunanya.\\n„Ö§„Ö§',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 13, 41),\n",
       "  'pengguna': 'diditisuu',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 11, 8),\n",
       "  'pengguna': 'BetaniaKrisna',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 9, 4),\n",
       "  'pengguna': 'JuliKecebaday',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 6, 41),\n",
       "  'pengguna': 'bellazurra',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 6, 12),\n",
       "  'pengguna': 'sundarese',\n",
       "  'isi_tweet': 'RT @Sketsa_Rasa: „Ö§„Ö§\\nPercuma gaji jakarta, biaya hidup jogja, kalo suasana udah di padang mahsyar mah semua nggak ada gunanya.\\n„Ö§„Ö§',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 5, 8),\n",
       "  'pengguna': 'terracotta___',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 3, 41),\n",
       "  'pengguna': 'ketchupmanja',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 9, 3, 7),\n",
       "  'pengguna': 'hafiidhfajr',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 58, 23),\n",
       "  'pengguna': 'fitriamaliae',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 58, 9),\n",
       "  'pengguna': 'VickyBayuu',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 57, 43),\n",
       "  'pengguna': 'jeveuxvivre_95',\n",
       "  'isi_tweet': 'RT @Sketsa_Rasa: „Ö§„Ö§\\nPercuma gaji jakarta, biaya hidup jogja, kalo suasana udah di padang mahsyar mah semua nggak ada gunanya.\\n„Ö§„Ö§',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 55),\n",
       "  'pengguna': 'AndalCoi',\n",
       "  'isi_tweet': 'jual netflix premium antihold\\n\\nSHARING\\n30k/BULAN, 90K/3 BLN\\n\\nPRIVATE\\n135k/BLN, 330K/3BLN\\n\\n‚ö†Ô∏èAPP LAIN CEK PINNED\\n\\nsp‚Ä¶ https://t.co/4m6EfYszxY',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 52, 52),\n",
       "  'pengguna': 'Ika41165847',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 50, 43),\n",
       "  'pengguna': 'putfuisyafir',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 49, 56),\n",
       "  'pengguna': 'AfiAww',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 49, 54),\n",
       "  'pengguna': 'hekalanjimbb',\n",
       "  'isi_tweet': 'RT @Sketsa_Rasa: „Ö§„Ö§\\nPercuma gaji jakarta, biaya hidup jogja, kalo suasana udah di padang mahsyar mah semua nggak ada gunanya.\\n„Ö§„Ö§',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 46, 35),\n",
       "  'pengguna': 'ReniRendhud',\n",
       "  'isi_tweet': 'RT @Sketsa_Rasa: „Ö§„Ö§\\nPercuma gaji jakarta, biaya hidup jogja, kalo suasana udah di padang mahsyar mah semua nggak ada gunanya.\\n„Ö§„Ö§',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 46, 35),\n",
       "  'pengguna': 'sitifatimaaaa',\n",
       "  'isi_tweet': 'RT @Sketsa_Rasa: „Ö§„Ö§\\nPercuma gaji jakarta, biaya hidup jogja, kalo suasana udah di padang mahsyar mah semua nggak ada gunanya.\\n„Ö§„Ö§',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 42, 26),\n",
       "  'pengguna': 'LutviNurul2',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 42),\n",
       "  'pengguna': 'AndalCoi',\n",
       "  'isi_tweet': 'jual netflix premium antihold\\n\\nSHARING\\n30k/BULAN, 90K/3 BLN\\n\\nPRIVATE\\n135k/BLN, 330K/3BLN\\n\\n‚ö†Ô∏èAPP LAIN CEK PINNED\\n\\nsp‚Ä¶ https://t.co/DNPYzRssr2',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 41, 48),\n",
       "  'pengguna': 'amanduyy',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 40, 27),\n",
       "  'pengguna': 'Rijun15',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 40, 26),\n",
       "  'pengguna': 'sweet_momment',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 38, 31),\n",
       "  'pengguna': 'anasnfd',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 35, 6),\n",
       "  'pengguna': 'Lelyyy191',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'},\n",
       " {'tanggal_tweet': datetime.datetime(2020, 12, 17, 8, 33, 10),\n",
       "  'pengguna': 'kahfi_galih',\n",
       "  'isi_tweet': 'RT @maswonka: gaji Jakarta, biaya hidup Jogja, suasana biasa aja = Surabaya dan sekitarnya.',\n",
       "  'sentimen': 'negatif'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
